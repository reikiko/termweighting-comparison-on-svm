{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5706473f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - SVM with TFIDF Term Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70885a99",
   "metadata": {},
   "source": [
    "`SVM Kernel = Linear; Term Weighting = TFIDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0250310",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c9fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np \n",
    "import re #RegEx\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm #Import SVM Classification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #Count Vector Space Model\n",
    "from sklearn import metrics #Matrix Builder\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import KFold #Import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC #Support Vector Classifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6096a28",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436c826",
   "metadata": {},
   "source": [
    "*Dataset is already preprocessed before.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61070b56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>stemming</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#AyoTolakUUIKN \\n\\nProyek IKN membuka peluang ...</td>\n",
       "      <td>['proyek', 'ikn', 'buka', 'peluang', 'oligarki...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tolak UU IKN karena berpotensi merusak lingkun...</td>\n",
       "      <td>['tolak', 'uu', 'ikn', 'potensi', 'rusak', 'li...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UU IKN hanya akan merugikan rakyat dengan huta...</td>\n",
       "      <td>['uu', 'ikn', 'rugi', 'rakyat', 'hutang', 'rib...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jika UU ini diterapkan yang terjadi adalah mas...</td>\n",
       "      <td>['uu', 'terap', 'masyarakat', 'rasa', 'rugi', ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UU IKN Syarat kepentingan oligarki. Tolak n ba...</td>\n",
       "      <td>['uu', 'ikn', 'syarat', 'penting', 'oligarki',...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>Horee!! Kabar gembira gaes!\\nProses pemindahan...</td>\n",
       "      <td>['horee', 'kabar', 'gembira', 'proses', 'pinda...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>Juru Bicara Presiden RI Fadjroel Rachman menga...</td>\n",
       "      <td>['juru', 'bicara', 'presiden', 'ri', 'fadjroel...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>Pemerintah Indonesia mengajak Korea Selatan un...</td>\n",
       "      <td>['perintah', 'indonesia', 'ajak', 'korea', 'se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>@pikiran_rakyat masalah Jakarta tepatnya harus...</td>\n",
       "      <td>['jakarta', 'tepat', 'asai', 'hadap', 'selesai...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5891</th>\n",
       "      <td>Pemindahan Ibu Kota Negara ke Kalimantan Timur...</td>\n",
       "      <td>['pindah', 'kota', 'negara', 'kalimantan', 'ti...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5892 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "0     #AyoTolakUUIKN \\n\\nProyek IKN membuka peluang ...   \n",
       "1     Tolak UU IKN karena berpotensi merusak lingkun...   \n",
       "2     UU IKN hanya akan merugikan rakyat dengan huta...   \n",
       "3     Jika UU ini diterapkan yang terjadi adalah mas...   \n",
       "4     UU IKN Syarat kepentingan oligarki. Tolak n ba...   \n",
       "...                                                 ...   \n",
       "5887  Horee!! Kabar gembira gaes!\\nProses pemindahan...   \n",
       "5888  Juru Bicara Presiden RI Fadjroel Rachman menga...   \n",
       "5889  Pemerintah Indonesia mengajak Korea Selatan un...   \n",
       "5890  @pikiran_rakyat masalah Jakarta tepatnya harus...   \n",
       "5891  Pemindahan Ibu Kota Negara ke Kalimantan Timur...   \n",
       "\n",
       "                                               stemming  label  \n",
       "0     ['proyek', 'ikn', 'buka', 'peluang', 'oligarki...   -1.0  \n",
       "1     ['tolak', 'uu', 'ikn', 'potensi', 'rusak', 'li...   -1.0  \n",
       "2     ['uu', 'ikn', 'rugi', 'rakyat', 'hutang', 'rib...   -1.0  \n",
       "3     ['uu', 'terap', 'masyarakat', 'rasa', 'rugi', ...   -1.0  \n",
       "4     ['uu', 'ikn', 'syarat', 'penting', 'oligarki',...   -1.0  \n",
       "...                                                 ...    ...  \n",
       "5887  ['horee', 'kabar', 'gembira', 'proses', 'pinda...    1.0  \n",
       "5888  ['juru', 'bicara', 'presiden', 'ri', 'fadjroel...    1.0  \n",
       "5889  ['perintah', 'indonesia', 'ajak', 'korea', 'se...    1.0  \n",
       "5890  ['jakarta', 'tepat', 'asai', 'hadap', 'selesai...   -1.0  \n",
       "5891  ['pindah', 'kota', 'negara', 'kalimantan', 'ti...   -1.0  \n",
       "\n",
       "[5892 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/clean_tweets.csv')\n",
    "df #Print Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462bb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b79a6",
   "metadata": {},
   "source": [
    "*Count each labels total value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7829314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    3750\n",
       "-1.0    2142\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9d623",
   "metadata": {},
   "source": [
    "### Implementing TFIDF Feature Weighthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602db8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "TFIDF = transformer.fit_transform(vectorizer.fit_transform(df['stemming']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a018887",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6109)\t0.14315601373542752\n",
      "  (0, 5844)\t0.16622470060891656\n",
      "  (0, 4597)\t0.162865630853309\n",
      "  (0, 4230)\t0.2922233702990785\n",
      "  (0, 4012)\t0.1905257547058482\n",
      "  (0, 3265)\t0.3113803845039028\n",
      "  (0, 2075)\t0.10361096909940386\n",
      "  (0, 1075)\t0.7838492709064525\n",
      "  (0, 838)\t0.285557828291107\n",
      "  (1, 6109)\t0.21886047921909518\n",
      "  (1, 5844)\t0.25412846225624514\n",
      "  (1, 4902)\t0.46125329379223834\n",
      "  (1, 4597)\t0.2489930327534278\n",
      "  (1, 4485)\t0.39040563665728034\n",
      "  (1, 4012)\t0.2912805189977316\n",
      "  (1, 3377)\t0.2780686167500103\n",
      "  (1, 3310)\t0.3865002311618443\n",
      "  (1, 3174)\t0.3517238658165412\n",
      "  (1, 2075)\t0.15840303007709808\n",
      "  (2, 6109)\t0.18108261184102664\n",
      "  (2, 5945)\t0.4824219756668292\n",
      "  (2, 4886)\t0.32731851979175763\n",
      "  (2, 4813)\t0.4543325604065755\n",
      "  (2, 4678)\t0.21456625059371806\n",
      "  (2, 4597)\t0.20601393573698765\n",
      "  :\t:\n",
      "  (5890, 3377)\t0.1368655018974392\n",
      "  (5890, 2939)\t0.04388358516287563\n",
      "  (5890, 2615)\t0.319562052618311\n",
      "  (5890, 2480)\t0.319562052618311\n",
      "  (5890, 2324)\t0.255930669586185\n",
      "  (5890, 2321)\t0.24347665731987908\n",
      "  (5890, 2075)\t0.03898302236866214\n",
      "  (5890, 2013)\t0.21048410710993962\n",
      "  (5890, 1844)\t0.22573611229740043\n",
      "  (5890, 1082)\t0.16512750369704565\n",
      "  (5890, 319)\t0.27502279149682973\n",
      "  (5890, 283)\t0.2456320338191671\n",
      "  (5891, 5787)\t0.15739629542914216\n",
      "  (5891, 5505)\t0.42590772364151763\n",
      "  (5891, 4910)\t0.1953822890972671\n",
      "  (5891, 4398)\t0.13127429195342244\n",
      "  (5891, 4192)\t0.4499038314178372\n",
      "  (5891, 3820)\t0.07411230944354606\n",
      "  (5891, 2939)\t0.0730491751852276\n",
      "  (5891, 2783)\t0.4499038314178372\n",
      "  (5891, 2512)\t0.1461766134741342\n",
      "  (5891, 2428)\t0.2087138181031104\n",
      "  (5891, 2075)\t0.06489163589731287\n",
      "  (5891, 1360)\t0.20985562233660185\n",
      "  (5891, 398)\t0.45780644405913334\n"
     ]
    }
   ],
   "source": [
    "print(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98bb821",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfTransformer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/3mf6hlxs5l7747hv_jgt6fj40000gn/T/ipykernel_51051/2294864785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTFIDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfTransformer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "TFIDF\n",
    "print(transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459930a",
   "metadata": {},
   "source": [
    "*Separate label to its own representative array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d254cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for data in df['label']:\n",
    "    label.append(data)\n",
    "kolom = label.pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d8403",
   "metadata": {},
   "source": [
    "### Average SVM Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99efba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgSVM(k):\n",
    "    total = 0\n",
    "    for i in range(k): #Iterate for k times\n",
    "        total = total + accuracy[i]\n",
    "    print(\"SVM Average Accuracy :\", total / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5bdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d4054",
   "metadata": {},
   "source": [
    "*Finding best k for KFold Cross Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e126279",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds : 2 | Avg Accuracy : 0.875 | Max, Min : 0.877, 0.873\n",
      "\n",
      "\n",
      "Folds : 3 | Avg Accuracy : 0.879 | Max, Min : 0.881, 0.877\n",
      "\n",
      "\n",
      "Folds : 4 | Avg Accuracy : 0.878 | Max, Min : 0.889, 0.862\n",
      "\n",
      "\n",
      "Folds : 5 | Avg Accuracy : 0.881 | Max, Min : 0.893, 0.874\n",
      "\n",
      "\n",
      "Folds : 6 | Avg Accuracy : 0.881 | Max, Min : 0.891, 0.872\n",
      "\n",
      "\n",
      "Folds : 7 | Avg Accuracy : 0.881 | Max, Min : 0.893, 0.867\n",
      "\n",
      "\n",
      "Folds : 8 | Avg Accuracy : 0.882 | Max, Min : 0.901, 0.856\n",
      "\n",
      "\n",
      "Folds : 9 | Avg Accuracy : 0.882 | Max, Min : 0.898, 0.860\n",
      "\n",
      "\n",
      "Folds : 10 | Avg Accuracy : 0.880 | Max, Min : 0.895, 0.861\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folds = range(2,11)\n",
    "for k in folds:\n",
    "    accuracy=[]\n",
    "    kFoldCrossValidation = KFold(n_splits=k, random_state=50, shuffle = True)\n",
    "    for train, test in kFoldCrossValidation.split(TFIDF, label):\n",
    "        trainData, testData = TFIDF[train], TFIDF[test]\n",
    "        label = np.array(label)\n",
    "        trainData2, testData2 = label[train], label[test]\n",
    "        \n",
    "        SVM = SVC(kernel = 'linear', C = 1)\n",
    "        model = SVM.fit(trainData, trainData2)\n",
    "        prediksi = model.predict(testData)\n",
    "        \n",
    "        accuracy.append(accuracy_score(testData2, prediksi))\n",
    "        \n",
    "    print('Folds : %d | Avg Accuracy : %.3f | Max, Min : %.3f, %.3f' \n",
    "          % (k, Average(accuracy), max(accuracy), min(accuracy)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc038adf",
   "metadata": {},
   "source": [
    "### Implementing KFold with chosen K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f65ef4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Amount of Train Data:  5302\n",
      "Amount of Test Data:  590\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [   8   14   16   21   63   65   73   75   79   80   91   98  144  146\n",
      "  159  162  168  169  175  178  180  203  209  216  245  246  251  253\n",
      "  256  268  271  294  314  341  347  349  354  366  370  389  392  407\n",
      "  414  418  419  421  432  437  457  460  474  486  493  508  511  512\n",
      "  513  517  525  541  542  543  559  560  564  575  581  585  611  616\n",
      "  624  636  641  677  687  692  698  703  705  706  715  727  732  750\n",
      "  764  766  768  781  799  803  815  829  834  846  856  865  877  880\n",
      "  886  893  903  912  921  939  940  941  944  956  958  982  986  998\n",
      " 1002 1020 1021 1022 1045 1064 1074 1085 1112 1119 1145 1165 1175 1188\n",
      " 1192 1202 1205 1206 1211 1218 1228 1244 1247 1256 1259 1262 1263 1265\n",
      " 1271 1295 1298 1303 1314 1316 1331 1341 1368 1376 1378 1387 1401 1403\n",
      " 1416 1422 1433 1438 1446 1452 1471 1475 1477 1480 1490 1512 1534 1538\n",
      " 1541 1558 1564 1569 1581 1628 1632 1638 1639 1669 1670 1672 1676 1687\n",
      " 1693 1695 1696 1706 1709 1711 1713 1714 1727 1772 1790 1793 1795 1807\n",
      " 1826 1843 1857 1858 1875 1885 1906 1924 1928 1932 1938 1940 1945 1949\n",
      " 1974 1980 1984 1988 2000 2002 2010 2019 2027 2042 2044 2057 2058 2063\n",
      " 2065 2084 2096 2099 2103 2117 2135 2138 2141 2149 2152 2167 2184 2196\n",
      " 2198 2201 2227 2228 2236 2256 2259 2268 2284 2295 2302 2304 2314 2315\n",
      " 2319 2322 2326 2330 2337 2349 2361 2387 2397 2400 2401 2406 2408 2412\n",
      " 2424 2425 2434 2441 2452 2459 2464 2465 2490 2501 2521 2526 2534 2544\n",
      " 2564 2567 2576 2586 2596 2603 2608 2639 2652 2664 2679 2693 2696 2702\n",
      " 2724 2735 2741 2745 2757 2765 2768 2785 2790 2801 2832 2836 2839 2845\n",
      " 2846 2867 2873 2875 2879 2889 2920 2923 2935 2940 2951 2953 2964 2974\n",
      " 2976 2977 2998 3008 3014 3024 3053 3064 3075 3127 3136 3141 3149 3169\n",
      " 3176 3180 3191 3206 3207 3228 3239 3251 3274 3277 3288 3290 3303 3311\n",
      " 3314 3318 3332 3341 3355 3379 3389 3390 3402 3419 3431 3465 3467 3479\n",
      " 3487 3498 3514 3543 3545 3572 3593 3595 3596 3599 3610 3614 3639 3642\n",
      " 3653 3662 3672 3678 3680 3685 3691 3693 3709 3711 3713 3724 3734 3745\n",
      " 3755 3771 3785 3797 3809 3824 3861 3863 3869 3872 3877 3900 3907 3929\n",
      " 3932 3951 3965 3967 3969 4005 4047 4048 4071 4081 4084 4101 4108 4116\n",
      " 4122 4123 4129 4132 4136 4143 4147 4148 4156 4176 4188 4190 4217 4219\n",
      " 4231 4242 4259 4271 4288 4292 4337 4343 4345 4351 4368 4392 4393 4394\n",
      " 4395 4410 4419 4446 4471 4473 4499 4506 4512 4529 4554 4557 4558 4568\n",
      " 4579 4581 4584 4592 4623 4634 4665 4683 4706 4727 4736 4741 4755 4784\n",
      " 4786 4794 4805 4811 4833 4834 4857 4866 4871 4881 4890 4894 4910 4912\n",
      " 4920 4923 4925 4930 4934 4944 4960 4962 4970 4978 4983 4998 5013 5021\n",
      " 5042 5046 5050 5060 5062 5072 5080 5094 5096 5115 5120 5121 5122 5132\n",
      " 5133 5144 5163 5164 5167 5179 5191 5200 5207 5227 5279 5289 5308 5311\n",
      " 5315 5334 5335 5361 5381 5383 5386 5389 5407 5426 5433 5435 5444 5445\n",
      " 5460 5461 5473 5478 5490 5511 5515 5527 5530 5536 5541 5543 5569 5578\n",
      " 5579 5580 5587 5591 5592 5595 5601 5606 5607 5635 5682 5689 5695 5708\n",
      " 5725 5733 5738 5769 5773 5786 5787 5789 5790 5805 5838 5851 5859 5867\n",
      " 5880 5885]\n",
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      " -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.\n",
      " -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[174  42]\n",
      " [ 21 353]]\n",
      "\n",
      "SVM Accuracy :  0.8932203389830509\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.94      0.92       374\n",
      "          -1       0.89      0.81      0.85       216\n",
      "\n",
      "    accuracy                           0.89       590\n",
      "   macro avg       0.89      0.87      0.88       590\n",
      "weighted avg       0.89      0.89      0.89       590\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5302\n",
      "Amount of Test Data:  590\n",
      "\n",
      "Train Data: \n",
      " [   1    2    3 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [   0    4   40   67   68   87   88  100  118  123  124  152  156  160\n",
      "  163  202  219  236  252  270  283  301  304  307  311  369  383  384\n",
      "  401  404  428  429  441  443  446  453  455  473  498  500  502  505\n",
      "  515  520  526  537  548  561  562  567  576  578  580  589  598  608\n",
      "  612  625  637  646  650  662  669  675  697  707  708  713  728  731\n",
      "  744  756  784  787  805  840  889  897  901  905  914  916  934  942\n",
      "  965  971  976  977 1009 1010 1030 1036 1057 1066 1072 1089 1095 1102\n",
      " 1106 1127 1128 1142 1173 1184 1187 1191 1197 1212 1216 1219 1227 1235\n",
      " 1237 1261 1268 1332 1335 1338 1362 1393 1405 1426 1431 1435 1467 1468\n",
      " 1488 1492 1502 1503 1508 1528 1533 1539 1560 1576 1586 1587 1593 1612\n",
      " 1622 1629 1642 1653 1655 1657 1662 1664 1697 1700 1708 1717 1719 1732\n",
      " 1733 1735 1740 1747 1755 1763 1765 1767 1768 1769 1776 1791 1794 1820\n",
      " 1840 1865 1892 1898 1905 1913 1934 1936 1939 1954 1962 1964 1966 1975\n",
      " 1981 1996 2001 2025 2032 2039 2043 2059 2060 2066 2077 2101 2107 2121\n",
      " 2123 2132 2133 2136 2137 2144 2151 2155 2160 2162 2163 2164 2166 2197\n",
      " 2211 2222 2223 2250 2273 2285 2307 2318 2334 2354 2355 2414 2431 2450\n",
      " 2477 2495 2509 2513 2519 2527 2535 2540 2549 2560 2575 2594 2615 2617\n",
      " 2623 2628 2630 2633 2650 2670 2675 2683 2698 2718 2725 2740 2743 2746\n",
      " 2747 2753 2760 2763 2783 2794 2798 2799 2812 2819 2820 2826 2849 2852\n",
      " 2855 2857 2862 2865 2882 2883 2890 2932 2957 2983 2997 3016 3031 3043\n",
      " 3067 3083 3091 3104 3119 3122 3124 3128 3139 3140 3148 3158 3186 3196\n",
      " 3198 3205 3210 3223 3248 3253 3254 3278 3292 3293 3301 3310 3319 3362\n",
      " 3393 3395 3405 3412 3418 3437 3439 3459 3471 3481 3482 3492 3496 3505\n",
      " 3519 3522 3525 3526 3533 3540 3564 3573 3597 3600 3611 3621 3625 3626\n",
      " 3630 3646 3656 3657 3674 3684 3694 3701 3706 3720 3728 3732 3752 3761\n",
      " 3773 3775 3790 3806 3811 3827 3831 3836 3844 3873 3878 3880 3887 3890\n",
      " 3916 3917 3944 3954 3989 3994 3995 4015 4036 4037 4053 4054 4067 4072\n",
      " 4076 4089 4090 4094 4098 4100 4103 4109 4112 4126 4134 4138 4141 4161\n",
      " 4166 4168 4218 4224 4230 4254 4256 4258 4262 4273 4308 4310 4311 4317\n",
      " 4322 4323 4330 4336 4338 4358 4361 4363 4365 4373 4397 4399 4401 4406\n",
      " 4422 4431 4432 4447 4451 4456 4458 4462 4470 4477 4490 4505 4508 4525\n",
      " 4531 4543 4551 4559 4570 4577 4589 4590 4604 4605 4606 4610 4612 4624\n",
      " 4631 4638 4648 4653 4661 4671 4674 4685 4691 4696 4698 4726 4748 4766\n",
      " 4787 4793 4799 4812 4826 4829 4837 4844 4849 4856 4858 4861 4885 4900\n",
      " 4901 4909 4911 4917 4919 4946 4961 4977 4981 4989 4995 4997 5015 5030\n",
      " 5039 5048 5073 5089 5093 5098 5101 5143 5158 5159 5181 5182 5208 5211\n",
      " 5217 5225 5230 5240 5243 5246 5250 5256 5257 5260 5266 5273 5274 5278\n",
      " 5281 5298 5299 5314 5322 5325 5336 5339 5346 5347 5352 5355 5378 5392\n",
      " 5408 5410 5414 5418 5422 5447 5450 5453 5457 5475 5484 5498 5507 5517\n",
      " 5522 5539 5550 5552 5556 5561 5564 5572 5574 5581 5602 5630 5633 5637\n",
      " 5645 5650 5653 5662 5677 5684 5688 5710 5735 5745 5748 5761 5767 5768\n",
      " 5785 5788 5796 5803 5804 5811 5812 5849 5852 5853 5856 5863 5864 5877\n",
      " 5883 5888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.\n",
      " -1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      "  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1.\n",
      " -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
      "  1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.\n",
      " -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[167  60]\n",
      " [ 19 344]]\n",
      "\n",
      "SVM Accuracy :  0.8661016949152542\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.95      0.90       363\n",
      "          -1       0.90      0.74      0.81       227\n",
      "\n",
      "    accuracy                           0.87       590\n",
      "   macro avg       0.87      0.84      0.85       590\n",
      "weighted avg       0.87      0.87      0.86       590\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5888 5889 5890]\n",
      "\n",
      "Test Data: \n",
      " [   5    6   12   13   22   24   25   47   49   55   66   74   85   86\n",
      "   90  108  122  149  158  185  204  210  230  233  241  248  285  309\n",
      "  328  331  343  345  353  356  368  374  376  386  387  396  403  410\n",
      "  438  452  461  480  506  534  553  570  571  572  597  599  600  621\n",
      "  639  644  647  660  672  682  686  695  696  714  719  729  733  742\n",
      "  745  747  748  754  765  777  783  801  802  820  839  843  845  859\n",
      "  860  898  913  920  922  927  931  932  938  951  973  974  979 1000\n",
      " 1001 1016 1018 1040 1044 1049 1068 1069 1078 1091 1114 1115 1120 1125\n",
      " 1129 1148 1151 1166 1176 1194 1225 1233 1238 1242 1245 1251 1254 1280\n",
      " 1288 1293 1304 1327 1329 1349 1353 1358 1369 1379 1396 1428 1444 1461\n",
      " 1465 1466 1489 1526 1537 1542 1548 1553 1557 1562 1567 1570 1572 1577\n",
      " 1590 1603 1607 1615 1627 1689 1701 1715 1718 1744 1750 1758 1761 1764\n",
      " 1782 1785 1787 1803 1805 1824 1839 1844 1848 1854 1867 1868 1874 1880\n",
      " 1882 1893 1915 1929 1970 1983 1986 1990 2020 2021 2038 2048 2050 2051\n",
      " 2054 2062 2067 2076 2081 2083 2085 2088 2094 2106 2113 2122 2125 2128\n",
      " 2139 2140 2182 2185 2200 2206 2209 2212 2221 2233 2235 2258 2275 2278\n",
      " 2291 2313 2316 2339 2347 2352 2365 2376 2378 2411 2413 2463 2471 2481\n",
      " 2506 2507 2510 2523 2541 2551 2555 2557 2558 2569 2581 2588 2602 2605\n",
      " 2613 2618 2640 2643 2644 2662 2667 2672 2673 2677 2686 2711 2716 2744\n",
      " 2759 2762 2789 2791 2792 2793 2803 2830 2858 2859 2860 2876 2897 2901\n",
      " 2916 2931 2944 2946 2948 2949 2960 2962 2986 2994 3023 3039 3042 3044\n",
      " 3062 3068 3071 3072 3088 3089 3097 3106 3135 3138 3143 3151 3164 3168\n",
      " 3170 3189 3195 3199 3208 3209 3211 3232 3234 3238 3242 3249 3273 3275\n",
      " 3295 3302 3325 3348 3356 3364 3377 3382 3383 3422 3426 3438 3440 3452\n",
      " 3453 3456 3457 3462 3464 3480 3490 3513 3524 3552 3557 3569 3582 3585\n",
      " 3608 3631 3632 3637 3650 3658 3660 3661 3666 3679 3695 3705 3731 3735\n",
      " 3749 3762 3769 3770 3772 3783 3786 3789 3791 3804 3814 3817 3819 3826\n",
      " 3828 3837 3841 3842 3852 3854 3855 3858 3860 3870 3875 3885 3886 3893\n",
      " 3899 3931 3941 3947 3953 3957 3961 3968 3970 3971 3974 3978 3982 3985\n",
      " 3987 3997 4013 4017 4023 4035 4068 4070 4078 4104 4121 4124 4128 4139\n",
      " 4144 4145 4154 4160 4162 4172 4173 4185 4186 4187 4189 4199 4201 4208\n",
      " 4210 4223 4225 4244 4282 4285 4312 4329 4335 4348 4353 4381 4435 4450\n",
      " 4461 4463 4465 4476 4481 4509 4514 4516 4519 4555 4587 4613 4639 4640\n",
      " 4652 4654 4682 4692 4703 4715 4745 4749 4752 4769 4772 4785 4789 4795\n",
      " 4797 4815 4818 4822 4824 4825 4835 4855 4868 4875 4876 4880 4889 4892\n",
      " 4902 4906 4913 4915 4942 4957 4972 4974 4975 5000 5007 5011 5016 5024\n",
      " 5026 5055 5057 5078 5082 5088 5099 5105 5107 5123 5124 5138 5140 5183\n",
      " 5186 5197 5198 5199 5223 5238 5262 5264 5283 5293 5303 5305 5321 5327\n",
      " 5330 5345 5350 5367 5371 5373 5384 5397 5423 5448 5467 5486 5492 5503\n",
      " 5514 5516 5518 5520 5563 5568 5571 5596 5604 5615 5616 5622 5632 5644\n",
      " 5652 5665 5666 5680 5687 5701 5702 5713 5714 5722 5723 5732 5736 5740\n",
      " 5746 5747 5749 5754 5757 5759 5762 5802 5827 5836 5840 5857 5862 5870\n",
      " 5891]\n",
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.\n",
      "  1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1.\n",
      "  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      " -1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      " -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1.\n",
      "  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[175  42]\n",
      " [ 26 346]]\n",
      "\n",
      "SVM Accuracy :  0.8845500848896435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.93      0.91       372\n",
      "          -1       0.87      0.81      0.84       217\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.88      0.87      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [   3   23   36   45   50   58   69  106  111  115  142  153  166  174\n",
      "  176  190  192  201  215  222  249  254  267  272  276  284  288  291\n",
      "  293  298  310  313  327  329  336  363  364  375  385  417  444  458\n",
      "  464  477  479  495  497  504  509  522  527  530  531  535  550  568\n",
      "  579  595  610  619  622  629  633  638  643  655  671  690  702  711\n",
      "  721  734  737  758  772  780  789  791  793  808  809  810  823  831\n",
      "  836  868  919  945  946  948  955  959  967  970  972  981  984  999\n",
      " 1006 1012 1013 1023 1058 1059 1071 1079 1100 1105 1109 1130 1135 1152\n",
      " 1159 1172 1185 1200 1201 1210 1217 1224 1246 1267 1270 1276 1300 1301\n",
      " 1302 1307 1346 1367 1377 1394 1395 1398 1407 1411 1427 1436 1439 1441\n",
      " 1442 1449 1454 1462 1479 1501 1513 1520 1527 1529 1550 1561 1573 1597\n",
      " 1606 1608 1621 1637 1648 1659 1663 1679 1683 1691 1702 1705 1725 1737\n",
      " 1738 1739 1741 1749 1751 1759 1781 1786 1797 1804 1811 1815 1827 1831\n",
      " 1841 1855 1876 1888 1895 1907 1912 1941 1946 1958 1977 1978 1997 2013\n",
      " 2018 2024 2031 2035 2037 2082 2089 2100 2104 2105 2114 2142 2147 2153\n",
      " 2157 2171 2178 2207 2216 2237 2245 2263 2282 2289 2308 2311 2333 2336\n",
      " 2345 2353 2369 2385 2395 2407 2428 2432 2436 2437 2448 2454 2456 2467\n",
      " 2483 2488 2491 2498 2502 2512 2524 2532 2547 2559 2572 2578 2580 2583\n",
      " 2593 2597 2612 2637 2659 2678 2680 2681 2714 2722 2727 2728 2755 2764\n",
      " 2786 2808 2816 2822 2825 2833 2834 2837 2854 2868 2878 2893 2909 2911\n",
      " 2914 2937 2956 2966 2972 2978 2979 2988 3002 3040 3045 3047 3061 3065\n",
      " 3066 3076 3081 3093 3098 3101 3107 3109 3110 3113 3121 3161 3167 3202\n",
      " 3203 3220 3227 3240 3263 3280 3287 3294 3306 3336 3347 3353 3361 3386\n",
      " 3396 3400 3409 3417 3428 3430 3432 3441 3446 3485 3488 3508 3511 3515\n",
      " 3517 3518 3547 3550 3559 3563 3581 3583 3584 3598 3602 3604 3607 3635\n",
      " 3636 3640 3643 3649 3652 3692 3696 3698 3702 3726 3727 3729 3774 3777\n",
      " 3784 3807 3808 3813 3823 3829 3856 3857 3871 3892 3898 3911 3913 3915\n",
      " 3918 3919 3923 3948 3959 3972 3981 4008 4034 4073 4074 4095 4102 4105\n",
      " 4125 4130 4150 4163 4167 4171 4177 4182 4195 4222 4247 4249 4251 4252\n",
      " 4257 4263 4264 4270 4272 4278 4295 4306 4315 4318 4324 4325 4327 4346\n",
      " 4350 4357 4364 4366 4367 4370 4371 4382 4388 4391 4396 4398 4403 4415\n",
      " 4425 4430 4442 4449 4460 4482 4500 4502 4504 4522 4535 4541 4544 4552\n",
      " 4553 4556 4564 4566 4569 4585 4586 4595 4617 4625 4627 4636 4651 4655\n",
      " 4679 4681 4687 4702 4704 4728 4737 4739 4758 4760 4761 4765 4774 4777\n",
      " 4781 4790 4801 4803 4813 4830 4840 4863 4864 4874 4896 4921 4932 4935\n",
      " 4945 4948 4949 4951 4956 4963 4969 4979 4982 4987 4991 4994 5006 5014\n",
      " 5036 5056 5065 5068 5071 5076 5085 5090 5095 5108 5116 5128 5129 5130\n",
      " 5142 5148 5174 5192 5194 5196 5203 5204 5209 5213 5220 5228 5241 5261\n",
      " 5265 5276 5280 5287 5297 5307 5326 5332 5349 5351 5356 5359 5366 5368\n",
      " 5369 5372 5375 5385 5401 5415 5439 5469 5470 5485 5497 5519 5531 5534\n",
      " 5553 5555 5566 5573 5590 5610 5620 5636 5651 5657 5663 5667 5672 5676\n",
      " 5698 5699 5717 5724 5766 5772 5780 5782 5792 5816 5820 5841 5866 5876\n",
      " 5887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.\n",
      "  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.\n",
      " -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      " -1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      " -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.\n",
      "  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.\n",
      " -1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[153  45]\n",
      " [ 22 369]]\n",
      "\n",
      "SVM Accuracy :  0.8862478777589134\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.94      0.92       391\n",
      "          -1       0.87      0.77      0.82       198\n",
      "\n",
      "    accuracy                           0.89       589\n",
      "   macro avg       0.88      0.86      0.87       589\n",
      "weighted avg       0.89      0.89      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    3    4 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [   1    2    9   17   18   27   29   32   39   53   54   76   83   89\n",
      "   94  102  107  114  116  131  150  154  171  179  182  197  198  227\n",
      "  231  235  240  242  258  266  277  286  297  299  303  319  326  330\n",
      "  339  372  393  398  406  416  420  423  426  430  431  447  449  466\n",
      "  468  476  528  540  545  549  551  565  582  586  591  592  604  614\n",
      "  617  618  632  634  648  652  654  664  700  716  720  722  724  736\n",
      "  746  761  762  769  770  774  776  798  806  817  835  837  838  847\n",
      "  853  863  864  867  869  870  875  885  887  904  906  925  929  935\n",
      "  947  953  993 1019 1029 1034 1046 1056 1060 1084 1096 1113 1133 1146\n",
      " 1149 1150 1156 1164 1168 1169 1171 1186 1199 1203 1207 1230 1240 1243\n",
      " 1253 1255 1281 1309 1317 1323 1342 1348 1350 1352 1359 1382 1400 1418\n",
      " 1420 1421 1424 1447 1453 1460 1482 1483 1485 1494 1505 1514 1516 1523\n",
      " 1531 1547 1549 1554 1579 1600 1605 1609 1619 1624 1636 1651 1654 1667\n",
      " 1671 1674 1677 1678 1681 1688 1692 1729 1730 1742 1757 1771 1779 1800\n",
      " 1806 1814 1819 1856 1866 1889 1894 1903 1919 1922 1930 1935 1951 1957\n",
      " 1963 1967 1968 1973 1989 1992 1995 1999 2029 2047 2068 2071 2086 2092\n",
      " 2111 2158 2165 2172 2214 2226 2231 2249 2252 2255 2262 2269 2270 2279\n",
      " 2283 2288 2296 2303 2312 2321 2323 2324 2343 2346 2357 2359 2380 2383\n",
      " 2384 2396 2419 2420 2421 2426 2427 2438 2458 2492 2497 2499 2511 2518\n",
      " 2530 2533 2548 2550 2554 2570 2571 2573 2606 2611 2622 2624 2625 2635\n",
      " 2647 2665 2674 2682 2691 2694 2699 2707 2721 2730 2736 2748 2749 2770\n",
      " 2774 2796 2802 2828 2841 2843 2866 2872 2896 2898 2904 2906 2958 2959\n",
      " 2961 2963 2973 2981 3001 3012 3021 3027 3036 3052 3056 3069 3070 3073\n",
      " 3080 3084 3090 3096 3115 3153 3154 3155 3157 3178 3179 3181 3184 3212\n",
      " 3215 3231 3237 3241 3262 3271 3282 3299 3305 3317 3337 3365 3373 3374\n",
      " 3385 3387 3407 3410 3413 3434 3436 3448 3449 3451 3493 3520 3523 3530\n",
      " 3535 3536 3539 3551 3554 3571 3576 3579 3586 3589 3590 3612 3624 3654\n",
      " 3668 3669 3670 3697 3699 3703 3708 3712 3742 3748 3750 3751 3768 3776\n",
      " 3787 3793 3805 3830 3840 3843 3846 3847 3851 3879 3894 3906 3908 3912\n",
      " 3922 3934 3937 3942 3943 3952 3958 3964 3977 3983 3984 3988 3991 4006\n",
      " 4022 4026 4039 4041 4046 4051 4057 4066 4097 4099 4113 4117 4131 4137\n",
      " 4165 4193 4198 4200 4205 4214 4220 4233 4239 4261 4266 4286 4290 4321\n",
      " 4328 4333 4352 4355 4374 4375 4378 4405 4409 4412 4423 4428 4433 4445\n",
      " 4457 4467 4478 4483 4501 4521 4530 4538 4549 4565 4576 4578 4580 4620\n",
      " 4628 4647 4656 4666 4670 4675 4690 4694 4695 4697 4717 4725 4751 4759\n",
      " 4792 4796 4808 4809 4816 4819 4821 4836 4838 4841 4845 4879 4888 4898\n",
      " 4926 4947 4952 4976 4999 5004 5005 5017 5018 5019 5027 5031 5035 5037\n",
      " 5053 5067 5087 5109 5119 5127 5150 5152 5154 5168 5170 5173 5188 5226\n",
      " 5249 5286 5288 5296 5300 5316 5319 5338 5342 5344 5354 5364 5374 5377\n",
      " 5394 5396 5409 5429 5451 5471 5472 5476 5506 5526 5537 5540 5584 5588\n",
      " 5612 5617 5621 5641 5647 5648 5649 5654 5661 5674 5679 5685 5696 5705\n",
      " 5706 5709 5737 5753 5775 5791 5799 5807 5814 5815 5818 5823 5846 5847\n",
      " 5873]\n",
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      " -1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      " -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
      "  1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.\n",
      "  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.\n",
      " -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      " -1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[183  43]\n",
      " [ 19 344]]\n",
      "\n",
      "SVM Accuracy :  0.8947368421052632\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.95      0.92       363\n",
      "          -1       0.91      0.81      0.86       226\n",
      "\n",
      "    accuracy                           0.89       589\n",
      "   macro avg       0.90      0.88      0.89       589\n",
      "weighted avg       0.90      0.89      0.89       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [  10   15   19   33   38   43   48   62   84  119  126  127  129  138\n",
      "  143  157  165  186  189  194  208  218  243  265  269  273  275  279\n",
      "  296  300  305  312  318  333  338  344  358  359  379  381  433  434\n",
      "  445  456  462  463  491  496  503  519  521  555  566  583  601  602\n",
      "  620  626  640  642  656  665  668  679  723  725  752  753  757  759\n",
      "  760  782  786  794  797  800  828  841  857  861  872  878  882  907\n",
      "  909  911  928  954  963  969  988 1003 1005 1007 1017 1033 1038 1047\n",
      " 1048 1053 1055 1073 1076 1086 1090 1123 1132 1138 1153 1163 1170 1181\n",
      " 1182 1183 1190 1195 1208 1215 1231 1232 1234 1236 1272 1273 1284 1286\n",
      " 1319 1330 1339 1351 1360 1361 1365 1366 1392 1399 1402 1408 1410 1412\n",
      " 1419 1423 1430 1457 1464 1486 1499 1507 1509 1515 1522 1535 1543 1544\n",
      " 1546 1565 1582 1584 1598 1616 1631 1634 1640 1652 1658 1666 1694 1703\n",
      " 1721 1743 1745 1770 1778 1783 1792 1813 1816 1829 1835 1837 1846 1847\n",
      " 1860 1864 1870 1873 1878 1890 1908 1910 1916 1918 1926 1947 1969 1982\n",
      " 1987 2006 2008 2015 2028 2030 2033 2053 2055 2061 2064 2073 2075 2080\n",
      " 2090 2124 2127 2148 2159 2175 2183 2186 2187 2193 2194 2215 2239 2240\n",
      " 2243 2265 2266 2271 2287 2294 2300 2340 2351 2364 2371 2374 2375 2389\n",
      " 2390 2403 2404 2405 2422 2430 2435 2457 2468 2470 2474 2500 2503 2514\n",
      " 2516 2517 2525 2528 2531 2543 2545 2561 2563 2600 2621 2638 2657 2676\n",
      " 2685 2687 2703 2709 2710 2713 2731 2732 2750 2769 2776 2779 2784 2795\n",
      " 2797 2805 2814 2815 2818 2823 2824 2844 2861 2863 2864 2870 2885 2902\n",
      " 2903 2917 2921 2922 2930 2941 2947 2965 2967 2968 2969 2971 3003 3004\n",
      " 3006 3007 3010 3017 3026 3034 3063 3079 3082 3087 3114 3120 3131 3159\n",
      " 3166 3171 3172 3173 3182 3192 3201 3222 3226 3230 3233 3243 3267 3281\n",
      " 3307 3316 3321 3322 3331 3335 3338 3340 3346 3350 3358 3359 3369 3375\n",
      " 3388 3401 3403 3404 3411 3420 3458 3466 3469 3477 3489 3507 3512 3516\n",
      " 3542 3562 3567 3568 3574 3594 3609 3618 3620 3623 3629 3633 3647 3651\n",
      " 3659 3665 3683 3716 3722 3730 3737 3740 3746 3778 3794 3798 3815 3816\n",
      " 3821 3834 3838 3839 3850 3859 3868 3901 3905 3927 3928 3930 3936 3960\n",
      " 3973 3979 3986 3993 4016 4027 4029 4031 4040 4050 4058 4063 4075 4077\n",
      " 4083 4107 4149 4164 4178 4183 4203 4215 4221 4241 4243 4265 4268 4279\n",
      " 4305 4326 4339 4341 4342 4344 4349 4369 4383 4384 4389 4400 4408 4420\n",
      " 4466 4468 4498 4524 4542 4563 4575 4591 4598 4600 4601 4621 4635 4643\n",
      " 4658 4667 4668 4672 4680 4710 4714 4720 4721 4723 4724 4734 4753 4757\n",
      " 4764 4767 4775 4782 4804 4814 4851 4852 4854 4862 4878 4884 4887 4897\n",
      " 4939 4940 4941 4943 4950 4966 4967 4968 4988 4992 5002 5023 5032 5045\n",
      " 5047 5052 5054 5061 5069 5086 5106 5111 5125 5131 5134 5136 5139 5161\n",
      " 5162 5165 5166 5171 5175 5189 5202 5231 5244 5252 5255 5258 5269 5282\n",
      " 5285 5290 5304 5312 5324 5333 5357 5370 5380 5382 5387 5402 5430 5436\n",
      " 5442 5458 5479 5483 5489 5491 5493 5494 5502 5505 5510 5513 5524 5533\n",
      " 5549 5575 5586 5603 5614 5668 5683 5686 5690 5700 5728 5734 5764 5765\n",
      " 5771 5779 5798 5810 5822 5829 5843 5848 5855 5858 5860 5868 5878 5879\n",
      " 5881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      " -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1.  1.\n",
      " -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      "  1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.\n",
      " -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      " -1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      " -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1.\n",
      " -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[178  44]\n",
      " [ 26 341]]\n",
      "\n",
      "SVM Accuracy :  0.8811544991511036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.93      0.91       367\n",
      "          -1       0.87      0.80      0.84       222\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.88      0.87      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [   7   11   31   42   64   81   82   93   96   99  109  113  117  139\n",
      "  141  145  167  187  200  214  217  225  226  232  237  238  244  247\n",
      "  264  278  282  287  292  315  316  322  335  337  352  357  360  378\n",
      "  382  395  397  399  400  405  422  436  448  450  467  469  470  484\n",
      "  485  487  499  514  523  532  544  556  563  569  607  627  631  663\n",
      "  673  689  704  710  741  771  785  788  792  795  796  811  822  826\n",
      "  832  842  848  852  858  883  891  908  930  937  943  952  957  966\n",
      "  968  985  987  990  994 1025 1026 1041 1052 1075 1097 1098 1110 1111\n",
      " 1116 1117 1122 1124 1158 1178 1180 1220 1221 1223 1249 1258 1264 1275\n",
      " 1277 1278 1285 1287 1291 1292 1310 1318 1320 1321 1322 1328 1344 1375\n",
      " 1388 1404 1425 1445 1470 1472 1473 1487 1493 1497 1504 1506 1517 1518\n",
      " 1540 1551 1566 1588 1589 1591 1617 1626 1644 1647 1660 1661 1665 1668\n",
      " 1680 1712 1731 1746 1756 1788 1801 1808 1818 1821 1830 1833 1838 1853\n",
      " 1859 1872 1900 1902 1909 1914 1917 1921 1925 1942 1943 1944 1965 1994\n",
      " 1998 2004 2005 2007 2012 2069 2070 2078 2079 2087 2093 2097 2129 2130\n",
      " 2134 2143 2168 2169 2170 2174 2192 2208 2244 2260 2267 2293 2310 2325\n",
      " 2327 2335 2356 2370 2393 2402 2410 2439 2440 2446 2447 2451 2453 2460\n",
      " 2469 2486 2493 2504 2515 2520 2522 2538 2539 2553 2556 2565 2566 2585\n",
      " 2587 2589 2620 2626 2642 2654 2658 2660 2684 2692 2704 2705 2720 2734\n",
      " 2739 2758 2766 2773 2778 2781 2800 2829 2840 2853 2856 2871 2887 2912\n",
      " 2919 2926 2929 2934 2939 2942 2950 2955 2980 2985 2992 3000 3005 3013\n",
      " 3025 3028 3033 3035 3055 3057 3058 3059 3060 3086 3092 3125 3129 3132\n",
      " 3152 3200 3216 3218 3224 3229 3252 3256 3257 3260 3266 3269 3279 3283\n",
      " 3296 3304 3312 3324 3326 3327 3345 3354 3357 3376 3380 3384 3391 3415\n",
      " 3427 3429 3450 3473 3484 3486 3501 3502 3528 3529 3532 3546 3556 3560\n",
      " 3566 3578 3606 3622 3641 3644 3645 3671 3673 3675 3677 3682 3690 3707\n",
      " 3715 3725 3733 3754 3756 3760 3764 3792 3795 3796 3799 3818 3820 3832\n",
      " 3835 3848 3853 3862 3874 3876 3891 3903 3904 3909 3910 3924 3935 3950\n",
      " 3955 3966 3996 4004 4009 4011 4032 4033 4056 4062 4064 4065 4080 4086\n",
      " 4092 4106 4119 4127 4133 4151 4174 4179 4192 4209 4211 4216 4229 4232\n",
      " 4240 4250 4253 4267 4274 4291 4301 4302 4304 4307 4313 4334 4359 4360\n",
      " 4376 4377 4390 4402 4413 4414 4424 4427 4429 4438 4443 4452 4454 4469\n",
      " 4475 4488 4517 4520 4533 4537 4539 4548 4562 4574 4596 4597 4611 4615\n",
      " 4632 4633 4645 4662 4663 4664 4701 4707 4709 4719 4729 4732 4743 4744\n",
      " 4750 4771 4779 4780 4798 4802 4806 4817 4828 4843 4848 4865 4870 4886\n",
      " 4895 4904 4914 4916 4924 4928 4929 4933 4936 4955 4964 4980 4985 5009\n",
      " 5012 5040 5041 5044 5051 5075 5092 5110 5146 5149 5157 5176 5180 5184\n",
      " 5187 5195 5210 5212 5235 5275 5284 5309 5318 5323 5328 5331 5340 5363\n",
      " 5376 5395 5398 5403 5405 5411 5441 5443 5446 5449 5452 5462 5465 5466\n",
      " 5487 5488 5496 5521 5545 5546 5558 5559 5560 5576 5593 5597 5598 5613\n",
      " 5623 5624 5626 5628 5629 5638 5639 5646 5660 5664 5669 5694 5697 5711\n",
      " 5712 5729 5751 5752 5760 5774 5777 5778 5795 5797 5828 5839 5869 5872\n",
      " 5886]\n",
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      " -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      " -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      " -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.\n",
      " -1.  1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[171  49]\n",
      " [ 33 336]]\n",
      "\n",
      "SVM Accuracy :  0.8607809847198642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.91      0.89       369\n",
      "          -1       0.84      0.78      0.81       220\n",
      "\n",
      "    accuracy                           0.86       589\n",
      "   macro avg       0.86      0.84      0.85       589\n",
      "weighted avg       0.86      0.86      0.86       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [  28   34   35   46   52   71   72   78  103  104  105  110  120  133\n",
      "  140  155  183  184  188  191  195  196  212  213  228  234  255  257\n",
      "  260  261  262  281  308  321  325  332  350  377  380  394  411  413\n",
      "  439  442  471  481  489  501  518  538  546  552  554  573  577  594\n",
      "  605  615  649  651  659  666  674  680  684  688  693  717  718  735\n",
      "  739  743  755  775  778  790  812  816  821  824  849  854  855  871\n",
      "  876  884  900  915  917  950  964 1008 1014 1015 1031 1032 1043 1054\n",
      " 1062 1065 1070 1083 1093 1101 1104 1108 1126 1140 1141 1144 1161 1196\n",
      " 1226 1250 1252 1266 1279 1283 1289 1294 1296 1305 1308 1311 1334 1336\n",
      " 1340 1343 1355 1357 1373 1380 1381 1383 1385 1389 1390 1391 1406 1414\n",
      " 1415 1451 1458 1469 1478 1481 1510 1536 1545 1555 1563 1568 1571 1574\n",
      " 1580 1594 1596 1604 1613 1620 1633 1641 1643 1649 1650 1673 1682 1684\n",
      " 1698 1723 1734 1748 1753 1762 1784 1789 1823 1828 1845 1852 1862 1887\n",
      " 1899 1937 1952 1953 1955 1976 1993 2011 2026 2034 2036 2046 2072 2102\n",
      " 2108 2109 2131 2146 2156 2161 2179 2181 2188 2195 2205 2213 2229 2232\n",
      " 2281 2286 2292 2297 2299 2305 2332 2341 2342 2360 2377 2381 2388 2392\n",
      " 2394 2398 2399 2409 2443 2444 2445 2449 2455 2462 2472 2476 2489 2508\n",
      " 2529 2542 2577 2582 2584 2590 2595 2598 2601 2607 2609 2632 2634 2636\n",
      " 2646 2651 2666 2668 2688 2689 2697 2706 2708 2737 2756 2767 2772 2775\n",
      " 2787 2807 2811 2813 2821 2850 2877 2881 2888 2894 2900 2905 2907 2910\n",
      " 2913 2915 2918 2924 2928 2933 2952 2984 2987 2996 3011 3019 3030 3032\n",
      " 3037 3041 3048 3054 3077 3078 3095 3099 3102 3103 3112 3116 3118 3133\n",
      " 3134 3144 3145 3162 3163 3165 3174 3175 3177 3187 3188 3190 3213 3225\n",
      " 3245 3247 3255 3264 3272 3285 3289 3297 3309 3315 3329 3344 3378 3416\n",
      " 3433 3435 3443 3454 3455 3460 3461 3468 3475 3483 3495 3499 3500 3506\n",
      " 3527 3531 3548 3553 3555 3558 3570 3577 3580 3588 3591 3605 3615 3616\n",
      " 3617 3638 3655 3667 3676 3687 3700 3719 3739 3741 3743 3744 3766 3780\n",
      " 3782 3788 3802 3803 3812 3866 3881 3884 3889 3895 3897 3921 3925 3926\n",
      " 3933 3938 3939 3945 3949 3962 3963 3975 3992 4000 4001 4002 4019 4025\n",
      " 4042 4044 4049 4055 4059 4079 4082 4091 4114 4115 4118 4146 4159 4180\n",
      " 4184 4191 4202 4206 4207 4212 4235 4236 4238 4246 4275 4276 4277 4281\n",
      " 4284 4287 4300 4320 4380 4417 4426 4440 4441 4444 4459 4479 4484 4485\n",
      " 4486 4489 4492 4494 4495 4527 4532 4536 4546 4560 4583 4588 4593 4594\n",
      " 4602 4603 4609 4619 4642 4650 4657 4677 4684 4688 4693 4705 4708 4711\n",
      " 4718 4730 4733 4735 4740 4746 4762 4763 4768 4770 4823 4827 4831 4832\n",
      " 4850 4853 4859 4860 4869 4872 4882 4903 4937 4954 4958 4990 4996 5001\n",
      " 5008 5020 5022 5058 5077 5081 5083 5113 5117 5137 5145 5151 5155 5177\n",
      " 5178 5206 5218 5232 5236 5251 5294 5295 5301 5306 5313 5317 5320 5348\n",
      " 5379 5388 5399 5400 5406 5416 5421 5425 5428 5434 5474 5499 5501 5508\n",
      " 5509 5528 5529 5532 5538 5544 5551 5565 5570 5577 5583 5589 5609 5611\n",
      " 5631 5634 5640 5643 5655 5656 5670 5678 5691 5715 5716 5720 5727 5730\n",
      " 5763 5781 5784 5793 5809 5819 5825 5826 5832 5835 5837 5842 5844 5850\n",
      " 5884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      " -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      "  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[164  42]\n",
      " [ 26 357]]\n",
      "\n",
      "SVM Accuracy :  0.8845500848896435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.93      0.91       383\n",
      "          -1       0.86      0.80      0.83       206\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.88      0.86      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5889 5890 5891]\n",
      "\n",
      "Test Data: \n",
      " [  20   37   44   61   77   97  112  125  130  135  137  151  161  172\n",
      "  181  193  199  205  206  207  220  221  223  224  229  250  259  263\n",
      "  274  280  290  306  317  320  323  324  340  351  355  365  402  412\n",
      "  427  435  454  459  465  472  475  478  482  483  488  492  494  510\n",
      "  516  529  539  557  558  574  584  588  593  596  606  609  613  623\n",
      "  628  635  645  653  658  667  670  676  678  709  712  738  751  763\n",
      "  773  779  814  830  844  850  851  866  873  879  894  895  902  910\n",
      "  923  933  936  962  975  978  980  997 1011 1027 1035 1039 1042 1050\n",
      " 1061 1063 1067 1081 1082 1088 1092 1099 1107 1118 1134 1136 1139 1143\n",
      " 1154 1157 1160 1167 1174 1193 1204 1260 1282 1297 1306 1324 1325 1337\n",
      " 1345 1347 1354 1363 1371 1372 1374 1384 1397 1413 1429 1432 1437 1440\n",
      " 1455 1456 1484 1491 1496 1498 1500 1519 1524 1552 1556 1559 1575 1578\n",
      " 1595 1599 1610 1618 1623 1645 1646 1656 1685 1704 1707 1720 1722 1724\n",
      " 1726 1736 1752 1766 1773 1775 1799 1812 1822 1825 1842 1863 1869 1877\n",
      " 1879 1881 1884 1891 1897 1901 1904 1927 1959 1960 1972 1991 2003 2022\n",
      " 2023 2045 2052 2056 2091 2098 2118 2126 2145 2154 2189 2199 2210 2218\n",
      " 2219 2225 2230 2234 2238 2241 2242 2248 2251 2254 2261 2264 2272 2274\n",
      " 2276 2277 2280 2298 2301 2309 2317 2328 2331 2344 2348 2350 2358 2362\n",
      " 2363 2366 2367 2379 2386 2415 2416 2417 2418 2429 2442 2461 2466 2473\n",
      " 2475 2479 2480 2482 2496 2536 2537 2546 2562 2568 2579 2591 2599 2604\n",
      " 2614 2619 2641 2653 2661 2690 2717 2719 2726 2733 2751 2754 2780 2782\n",
      " 2804 2806 2809 2817 2831 2842 2848 2869 2880 2886 2891 2892 2895 2899\n",
      " 2943 2945 2970 2975 2991 2993 2995 3009 3029 3046 3049 3050 3074 3085\n",
      " 3105 3108 3123 3137 3147 3150 3183 3185 3194 3197 3217 3236 3244 3250\n",
      " 3259 3270 3298 3320 3339 3342 3343 3351 3352 3363 3366 3367 3392 3394\n",
      " 3397 3398 3408 3414 3424 3442 3444 3445 3463 3470 3491 3497 3510 3521\n",
      " 3537 3541 3561 3565 3575 3587 3592 3601 3613 3619 3627 3628 3681 3686\n",
      " 3688 3689 3704 3721 3723 3736 3757 3758 3781 3800 3801 3810 3822 3845\n",
      " 3849 3867 3902 3976 3990 3998 3999 4007 4014 4018 4020 4021 4028 4038\n",
      " 4043 4045 4061 4069 4085 4093 4110 4120 4140 4142 4152 4153 4170 4181\n",
      " 4194 4197 4204 4213 4234 4237 4245 4255 4297 4298 4299 4309 4316 4332\n",
      " 4340 4347 4354 4356 4362 4372 4385 4386 4411 4416 4418 4439 4455 4464\n",
      " 4472 4487 4491 4497 4503 4511 4513 4518 4526 4545 4550 4567 4571 4572\n",
      " 4599 4616 4622 4626 4630 4637 4641 4646 4669 4673 4686 4699 4700 4722\n",
      " 4738 4747 4754 4776 4778 4783 4788 4791 4810 4820 4839 4842 4846 4867\n",
      " 4891 4899 4905 4908 4922 4927 4938 4953 4971 4973 4986 4993 5003 5010\n",
      " 5025 5038 5059 5063 5066 5070 5074 5084 5103 5126 5135 5147 5156 5169\n",
      " 5172 5185 5190 5201 5205 5214 5219 5221 5222 5224 5234 5239 5245 5247\n",
      " 5254 5263 5268 5270 5277 5291 5292 5343 5353 5358 5390 5393 5404 5413\n",
      " 5417 5419 5420 5437 5454 5455 5456 5459 5463 5480 5481 5495 5535 5542\n",
      " 5548 5562 5585 5594 5599 5608 5658 5671 5675 5693 5704 5721 5731 5739\n",
      " 5743 5744 5758 5770 5776 5783 5794 5800 5817 5824 5830 5831 5834 5854\n",
      " 5882]\n",
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      " -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.\n",
      " -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      " -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      " -1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      " -1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1.\n",
      "  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.\n",
      "  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[169  46]\n",
      " [ 25 349]]\n",
      "\n",
      "SVM Accuracy :  0.8794567062818336\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.93      0.91       374\n",
      "          -1       0.87      0.79      0.83       215\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.88      0.86      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Train Data: \n",
      " [   0    1    2 ... 5887 5888 5891]\n",
      "\n",
      "Test Data: \n",
      " [  26   30   41   51   56   57   59   60   70   92   95  101  121  128\n",
      "  132  134  136  147  148  164  170  173  177  211  239  289  295  302\n",
      "  334  342  346  348  361  362  367  371  373  388  390  391  408  409\n",
      "  415  424  425  440  451  490  507  524  533  536  547  587  590  603\n",
      "  630  657  661  681  683  685  691  694  699  701  726  730  740  749\n",
      "  767  804  807  813  818  819  825  827  833  862  874  881  888  890\n",
      "  892  896  899  918  924  926  949  960  961  983  989  991  992  995\n",
      "  996 1004 1024 1028 1037 1051 1077 1080 1087 1094 1103 1121 1131 1137\n",
      " 1147 1155 1162 1177 1179 1189 1198 1209 1213 1214 1222 1229 1239 1241\n",
      " 1248 1257 1269 1274 1290 1299 1312 1313 1315 1326 1333 1356 1364 1370\n",
      " 1386 1409 1417 1434 1443 1448 1450 1459 1463 1474 1476 1495 1511 1521\n",
      " 1525 1530 1532 1583 1585 1592 1601 1602 1611 1614 1625 1630 1635 1675\n",
      " 1686 1690 1699 1710 1716 1728 1754 1760 1774 1777 1780 1796 1798 1802\n",
      " 1809 1810 1817 1832 1834 1836 1849 1850 1851 1861 1871 1883 1886 1896\n",
      " 1911 1920 1923 1931 1933 1948 1950 1956 1961 1971 1979 1985 2009 2014\n",
      " 2016 2017 2040 2041 2049 2074 2095 2110 2112 2115 2116 2119 2120 2150\n",
      " 2173 2176 2177 2180 2190 2191 2202 2203 2204 2217 2220 2224 2246 2247\n",
      " 2253 2257 2290 2306 2320 2329 2338 2368 2372 2373 2382 2391 2423 2433\n",
      " 2478 2484 2485 2487 2494 2505 2552 2574 2592 2610 2616 2627 2629 2631\n",
      " 2645 2648 2649 2655 2656 2663 2669 2671 2695 2700 2701 2712 2715 2723\n",
      " 2729 2738 2742 2752 2761 2771 2777 2788 2810 2827 2835 2838 2847 2851\n",
      " 2874 2884 2908 2925 2927 2936 2938 2954 2982 2989 2990 2999 3015 3018\n",
      " 3020 3022 3038 3051 3094 3100 3111 3117 3126 3130 3142 3146 3156 3160\n",
      " 3193 3204 3214 3219 3221 3235 3246 3258 3261 3265 3268 3276 3284 3286\n",
      " 3291 3300 3308 3313 3323 3328 3330 3333 3334 3349 3360 3368 3370 3371\n",
      " 3372 3381 3399 3406 3421 3423 3425 3447 3472 3474 3476 3478 3494 3503\n",
      " 3504 3509 3534 3538 3544 3549 3603 3634 3648 3663 3664 3710 3714 3717\n",
      " 3718 3738 3747 3753 3759 3763 3765 3767 3779 3825 3833 3864 3865 3882\n",
      " 3883 3888 3896 3914 3920 3940 3946 3956 3980 4003 4010 4012 4024 4030\n",
      " 4052 4060 4087 4088 4096 4111 4135 4155 4157 4158 4169 4175 4196 4226\n",
      " 4227 4228 4248 4260 4269 4280 4283 4289 4293 4294 4296 4303 4314 4319\n",
      " 4331 4379 4387 4404 4407 4421 4434 4436 4437 4448 4453 4474 4480 4493\n",
      " 4496 4507 4510 4515 4523 4528 4534 4540 4547 4561 4573 4582 4607 4608\n",
      " 4614 4618 4629 4644 4649 4659 4660 4676 4678 4689 4712 4713 4716 4731\n",
      " 4742 4756 4773 4800 4807 4847 4873 4877 4883 4893 4907 4918 4931 4959\n",
      " 4965 4984 5028 5029 5033 5034 5043 5049 5064 5079 5091 5097 5100 5102\n",
      " 5104 5112 5114 5118 5141 5153 5160 5193 5215 5216 5229 5233 5237 5242\n",
      " 5248 5253 5259 5267 5271 5272 5302 5310 5329 5337 5341 5360 5362 5365\n",
      " 5391 5412 5424 5427 5431 5432 5438 5440 5464 5468 5477 5482 5500 5504\n",
      " 5512 5523 5525 5547 5554 5557 5567 5582 5600 5605 5618 5619 5625 5627\n",
      " 5642 5659 5673 5681 5692 5703 5707 5718 5719 5726 5741 5742 5750 5755\n",
      " 5756 5801 5806 5808 5813 5821 5833 5845 5861 5865 5871 5874 5875 5889\n",
      " 5890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Prediction  : \n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.\n",
      " -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      " -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      " -1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      "  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.]\n",
      "\n",
      "Confusion Matrix: \n",
      " [[148  47]\n",
      " [ 28 366]]\n",
      "\n",
      "SVM Accuracy :  0.8726655348047538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.93      0.91       394\n",
      "          -1       0.84      0.76      0.80       195\n",
      "\n",
      "    accuracy                           0.87       589\n",
      "   macro avg       0.86      0.84      0.85       589\n",
      "weighted avg       0.87      0.87      0.87       589\n",
      "\n",
      "SVM Average Accuracy : 0.884971367730425\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation will iterate k=5 times\n",
    "kFoldCrossValidation = KFold(n_splits=10, random_state=50, shuffle = True)\n",
    "for train, test in kFoldCrossValidation.split(TFIDF, label):\n",
    "    \n",
    "    print(\"==========================================================================================\")\n",
    "    print(\"Amount of Train Data: \", len(train))\n",
    "    print(\"Amount of Test Data: \", len(test))\n",
    "    print(\"\\nTrain Data: \\n\", train)\n",
    "    print(\"\\nTest Data: \\n\", test)\n",
    "    #Initiate Train and Test Data then transform to TFIDF value. Then copy to new Train and Test variables. \n",
    "    trainData, testData = TFIDF[train], TFIDF[test]\n",
    "    label = np.array(label)\n",
    "    trainData2, testData2 = label[train], label[test]\n",
    "    \n",
    "    SVM = SVC(kernel = 'linear', C = 1)\n",
    "    model = SVM.fit(trainData, trainData2)\n",
    "    prediksi = model.predict(testData)\n",
    "    \n",
    "    print(\"\\nSVM Prediction  : \\n\", prediksi)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix: \\n\", metrics.confusion_matrix(testData2, prediksi))\n",
    "   \n",
    "    accuracy.append(accuracy_score(testData2, prediksi))\n",
    "    \n",
    "    print(\"\\nSVM Accuracy : \", accuracy_score(testData2, prediksi))\n",
    "    print()\\\n",
    "    \n",
    "    label_target = ['positif','negatif']\n",
    "    print(metrics.classification_report(testData2, prediksi, labels=[1,-1]))#Confussion Matrix\n",
    "    \n",
    "avgSVM(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1e42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
