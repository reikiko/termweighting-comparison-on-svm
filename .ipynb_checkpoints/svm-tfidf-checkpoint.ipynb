{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5706473f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - SVM with TFIDF Term Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70885a99",
   "metadata": {},
   "source": [
    "`SVM Kernel = Linear; Term Weighting = TFIDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0250310",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c9fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np \n",
    "import re #RegEx\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm #Import SVM Classification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #Count Vector Space Model\n",
    "from sklearn import metrics #Matrix Builder\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import KFold #Import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC #Support Vector Classifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6096a28",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436c826",
   "metadata": {},
   "source": [
    "*Dataset is already preprocessed before.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61070b56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>stemming</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#AyoTolakUUIKN \\n\\nProyek IKN membuka peluang ...</td>\n",
       "      <td>['proyek', 'ikn', 'buka', 'peluang', 'oligarki...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tolak UU IKN karena berpotensi merusak lingkun...</td>\n",
       "      <td>['tolak', 'uu', 'ikn', 'potensi', 'rusak', 'li...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UU IKN hanya akan merugikan rakyat dengan huta...</td>\n",
       "      <td>['uu', 'ikn', 'rugi', 'rakyat', 'hutang', 'rib...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jika UU ini diterapkan yang terjadi adalah mas...</td>\n",
       "      <td>['uu', 'terap', 'masyarakat', 'rasa', 'rugi', ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UU IKN Syarat kepentingan oligarki. Tolak n ba...</td>\n",
       "      <td>['uu', 'ikn', 'syarat', 'penting', 'oligarki',...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>Horee!! Kabar gembira gaes!\\nProses pemindahan...</td>\n",
       "      <td>['horee', 'kabar', 'gembira', 'proses', 'pinda...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>Juru Bicara Presiden RI Fadjroel Rachman menga...</td>\n",
       "      <td>['juru', 'bicara', 'presiden', 'ri', 'fadjroel...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>Pemerintah Indonesia mengajak Korea Selatan un...</td>\n",
       "      <td>['perintah', 'indonesia', 'ajak', 'korea', 'se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>@pikiran_rakyat masalah Jakarta tepatnya harus...</td>\n",
       "      <td>['jakarta', 'tepat', 'asai', 'hadap', 'selesai...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5891</th>\n",
       "      <td>Pemindahan Ibu Kota Negara ke Kalimantan Timur...</td>\n",
       "      <td>['pindah', 'kota', 'negara', 'kalimantan', 'ti...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5892 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "0     #AyoTolakUUIKN \\n\\nProyek IKN membuka peluang ...   \n",
       "1     Tolak UU IKN karena berpotensi merusak lingkun...   \n",
       "2     UU IKN hanya akan merugikan rakyat dengan huta...   \n",
       "3     Jika UU ini diterapkan yang terjadi adalah mas...   \n",
       "4     UU IKN Syarat kepentingan oligarki. Tolak n ba...   \n",
       "...                                                 ...   \n",
       "5887  Horee!! Kabar gembira gaes!\\nProses pemindahan...   \n",
       "5888  Juru Bicara Presiden RI Fadjroel Rachman menga...   \n",
       "5889  Pemerintah Indonesia mengajak Korea Selatan un...   \n",
       "5890  @pikiran_rakyat masalah Jakarta tepatnya harus...   \n",
       "5891  Pemindahan Ibu Kota Negara ke Kalimantan Timur...   \n",
       "\n",
       "                                               stemming  label  \n",
       "0     ['proyek', 'ikn', 'buka', 'peluang', 'oligarki...   -1.0  \n",
       "1     ['tolak', 'uu', 'ikn', 'potensi', 'rusak', 'li...   -1.0  \n",
       "2     ['uu', 'ikn', 'rugi', 'rakyat', 'hutang', 'rib...   -1.0  \n",
       "3     ['uu', 'terap', 'masyarakat', 'rasa', 'rugi', ...   -1.0  \n",
       "4     ['uu', 'ikn', 'syarat', 'penting', 'oligarki',...   -1.0  \n",
       "...                                                 ...    ...  \n",
       "5887  ['horee', 'kabar', 'gembira', 'proses', 'pinda...    1.0  \n",
       "5888  ['juru', 'bicara', 'presiden', 'ri', 'fadjroel...    1.0  \n",
       "5889  ['perintah', 'indonesia', 'ajak', 'korea', 'se...    1.0  \n",
       "5890  ['jakarta', 'tepat', 'asai', 'hadap', 'selesai...   -1.0  \n",
       "5891  ['pindah', 'kota', 'negara', 'kalimantan', 'ti...   -1.0  \n",
       "\n",
       "[5892 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/clean_tweets.csv')\n",
    "df #Print Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462bb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b79a6",
   "metadata": {},
   "source": [
    "*Count each labels total value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7829314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    3750\n",
       "-1.0    2142\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9d623",
   "metadata": {},
   "source": [
    "### Implementing TFIDF Feature Weighthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602db8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "# transformer = TfidfTransformer()\n",
    "# TFIDF = transformer.fit_transform(vectorizer.fit_transform(df['stemming']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "757c7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(use_idf = True ,max_features = 5000)\n",
    "x = tfidf_vect.fit(df['stemming'])\n",
    "TFIDF = x.transform(df['stemming'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a018887",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4802)\t0.14315601373542752\n",
      "  (0, 4537)\t0.16622470060891656\n",
      "  (0, 3308)\t0.162865630853309\n",
      "  (0, 3127)\t0.2922233702990785\n",
      "  (0, 3010)\t0.1905257547058482\n",
      "  (0, 2470)\t0.3113803845039028\n",
      "  (0, 1720)\t0.10361096909940386\n",
      "  (0, 1075)\t0.7838492709064525\n",
      "  (0, 838)\t0.285557828291107\n",
      "  (1, 4802)\t0.21886047921909518\n",
      "  (1, 4537)\t0.25412846225624514\n",
      "  (1, 3595)\t0.46125329379223834\n",
      "  (1, 3308)\t0.2489930327534278\n",
      "  (1, 3248)\t0.39040563665728034\n",
      "  (1, 3010)\t0.2912805189977316\n",
      "  (1, 2582)\t0.2780686167500103\n",
      "  (1, 2515)\t0.3865002311618443\n",
      "  (1, 2415)\t0.3517238658165412\n",
      "  (1, 1720)\t0.15840303007709808\n",
      "  (2, 4802)\t0.18108261184102664\n",
      "  (2, 4638)\t0.4824219756668292\n",
      "  (2, 3579)\t0.32731851979175763\n",
      "  (2, 3506)\t0.4543325604065755\n",
      "  (2, 3371)\t0.21456625059371806\n",
      "  (2, 3308)\t0.20601393573698765\n",
      "  :\t:\n",
      "  (5890, 3131)\t0.3144465580261046\n",
      "  (5890, 2931)\t0.04990982269454878\n",
      "  (5890, 2582)\t0.15342738756306706\n",
      "  (5890, 2297)\t0.049193870881259344\n",
      "  (5890, 1944)\t0.28690044962023814\n",
      "  (5890, 1941)\t0.27293939632187253\n",
      "  (5890, 1720)\t0.043700298456643784\n",
      "  (5890, 1670)\t0.2359544679244482\n",
      "  (5890, 1585)\t0.25305209500043707\n",
      "  (5890, 1082)\t0.18510933110107888\n",
      "  (5890, 319)\t0.3083028800879309\n",
      "  (5890, 283)\t0.2753555916444046\n",
      "  (5891, 4480)\t0.15739629542914216\n",
      "  (5891, 4198)\t0.42590772364151763\n",
      "  (5891, 3603)\t0.1953822890972671\n",
      "  (5891, 3203)\t0.13127429195342244\n",
      "  (5891, 3104)\t0.4499038314178372\n",
      "  (5891, 2931)\t0.07411230944354606\n",
      "  (5891, 2297)\t0.0730491751852276\n",
      "  (5891, 2211)\t0.4499038314178372\n",
      "  (5891, 2058)\t0.1461766134741342\n",
      "  (5891, 2018)\t0.2087138181031104\n",
      "  (5891, 1720)\t0.06489163589731287\n",
      "  (5891, 1348)\t0.20985562233660185\n",
      "  (5891, 398)\t0.45780644405913334\n"
     ]
    }
   ],
   "source": [
    "print(TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459930a",
   "metadata": {},
   "source": [
    "*Separate label to its own representative array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d254cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for data in df['label']:\n",
    "    label.append(data)\n",
    "kolom = label.pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d8403",
   "metadata": {},
   "source": [
    "### Average SVM Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99efba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgSVM(k):\n",
    "    total = 0\n",
    "    for i in range(k): #Iterate for k times\n",
    "        total = total + accuracy[i]\n",
    "    print(\"SVM Average Accuracy :\", total / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5bdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d4054",
   "metadata": {},
   "source": [
    "*Finding best k for KFold Cross Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e126279",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds : 2 | Avg Accuracy : 0.871 | Max, Min : 0.871, 0.870\n",
      "\n",
      "\n",
      "Folds : 3 | Avg Accuracy : 0.873 | Max, Min : 0.876, 0.870\n",
      "\n",
      "\n",
      "Folds : 4 | Avg Accuracy : 0.877 | Max, Min : 0.889, 0.872\n",
      "\n",
      "\n",
      "Folds : 5 | Avg Accuracy : 0.878 | Max, Min : 0.885, 0.872\n",
      "\n",
      "\n",
      "Folds : 6 | Avg Accuracy : 0.878 | Max, Min : 0.887, 0.864\n",
      "\n",
      "\n",
      "Folds : 7 | Avg Accuracy : 0.880 | Max, Min : 0.892, 0.868\n",
      "\n",
      "\n",
      "Folds : 8 | Avg Accuracy : 0.879 | Max, Min : 0.887, 0.867\n",
      "\n",
      "\n",
      "Folds : 9 | Avg Accuracy : 0.879 | Max, Min : 0.890, 0.870\n",
      "\n",
      "\n",
      "Folds : 10 | Avg Accuracy : 0.879 | Max, Min : 0.893, 0.864\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folds = range(2,11)\n",
    "for k in folds:\n",
    "    accuracy=[]\n",
    "    kFoldCrossValidation = KFold(n_splits=k, random_state=0, shuffle = True)\n",
    "    for train, test in kFoldCrossValidation.split(TFIDF, label):\n",
    "        trainData, testData = TFIDF[train], TFIDF[test]\n",
    "        label = np.array(label)\n",
    "        trainData2, testData2 = label[train], label[test]\n",
    "        \n",
    "        SVM = SVC(kernel = 'linear', C = 1)\n",
    "        model = SVM.fit(trainData, trainData2)\n",
    "        prediksi = model.predict(testData)\n",
    "        \n",
    "        accuracy.append(accuracy_score(testData2, prediksi))\n",
    "        \n",
    "    print('Folds : %d | Accuracy : %.3f | Max, Min : %.3f, %.3f' \n",
    "          % (k, Average(accuracy), max(accuracy), min(accuracy)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc038adf",
   "metadata": {},
   "source": [
    "### Implementing KFold with chosen K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f65ef4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Amount of Train Data:  5302\n",
      "Amount of Test Data:  590\n",
      "\n",
      "Confusion Matrix: \n",
      " [[172  46]\n",
      " [ 20 352]]\n",
      "\n",
      "SVM Accuracy :  0.888135593220339\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.95      0.91       372\n",
      "          -1       0.90      0.79      0.84       218\n",
      "\n",
      "    accuracy                           0.89       590\n",
      "   macro avg       0.89      0.87      0.88       590\n",
      "weighted avg       0.89      0.89      0.89       590\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5302\n",
      "Amount of Test Data:  590\n",
      "\n",
      "Confusion Matrix: \n",
      " [[171  47]\n",
      " [ 30 342]]\n",
      "\n",
      "SVM Accuracy :  0.8694915254237288\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.92      0.90       372\n",
      "          -1       0.85      0.78      0.82       218\n",
      "\n",
      "    accuracy                           0.87       590\n",
      "   macro avg       0.86      0.85      0.86       590\n",
      "weighted avg       0.87      0.87      0.87       590\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[159  48]\n",
      " [ 21 361]]\n",
      "\n",
      "SVM Accuracy :  0.8828522920203735\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.95      0.91       382\n",
      "          -1       0.88      0.77      0.82       207\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.88      0.86      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[150  49]\n",
      " [ 23 367]]\n",
      "\n",
      "SVM Accuracy :  0.8777589134125636\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.94      0.91       390\n",
      "          -1       0.87      0.75      0.81       199\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.87      0.85      0.86       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[180  38]\n",
      " [ 25 346]]\n",
      "\n",
      "SVM Accuracy :  0.8930390492359932\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.93      0.92       371\n",
      "          -1       0.88      0.83      0.85       218\n",
      "\n",
      "    accuracy                           0.89       589\n",
      "   macro avg       0.89      0.88      0.88       589\n",
      "weighted avg       0.89      0.89      0.89       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[175  45]\n",
      " [ 28 341]]\n",
      "\n",
      "SVM Accuracy :  0.8760611205432938\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.92      0.90       369\n",
      "          -1       0.86      0.80      0.83       220\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.87      0.86      0.87       589\n",
      "weighted avg       0.88      0.88      0.87       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[174  44]\n",
      " [ 27 344]]\n",
      "\n",
      "SVM Accuracy :  0.8794567062818336\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.93      0.91       371\n",
      "          -1       0.87      0.80      0.83       218\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.88      0.86      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[164  53]\n",
      " [ 27 345]]\n",
      "\n",
      "SVM Accuracy :  0.8641765704584041\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.93      0.90       372\n",
      "          -1       0.86      0.76      0.80       217\n",
      "\n",
      "    accuracy                           0.86       589\n",
      "   macro avg       0.86      0.84      0.85       589\n",
      "weighted avg       0.86      0.86      0.86       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[160  48]\n",
      " [ 20 361]]\n",
      "\n",
      "SVM Accuracy :  0.8845500848896435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.95      0.91       381\n",
      "          -1       0.89      0.77      0.82       208\n",
      "\n",
      "    accuracy                           0.88       589\n",
      "   macro avg       0.89      0.86      0.87       589\n",
      "weighted avg       0.88      0.88      0.88       589\n",
      "\n",
      "==========================================================================================\n",
      "Amount of Train Data:  5303\n",
      "Amount of Test Data:  589\n",
      "\n",
      "Confusion Matrix: \n",
      " [[174  45]\n",
      " [ 29 341]]\n",
      "\n",
      "SVM Accuracy :  0.8743633276740238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.92      0.90       370\n",
      "          -1       0.86      0.79      0.82       219\n",
      "\n",
      "    accuracy                           0.87       589\n",
      "   macro avg       0.87      0.86      0.86       589\n",
      "weighted avg       0.87      0.87      0.87       589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation will iterate k times\n",
    "kFoldCrossValidation = KFold(n_splits=10, random_state=0, shuffle = True)\n",
    "for train, test in kFoldCrossValidation.split(TFIDF, label):\n",
    "    \n",
    "    print(\"==========================================================================================\")\n",
    "    print(\"Amount of Train Data: \", len(train))\n",
    "    print(\"Amount of Test Data: \", len(test))\n",
    "#     print(\"\\nTrain Data: \\n\", train)\n",
    "#     print(\"\\nTest Data: \\n\", test)\n",
    "    #Initiate Train and Test Data then transform to TFIDF value. Then copy to new Train and Test variables. \n",
    "    trainData, testData = TFIDF[train], TFIDF[test]\n",
    "    label = np.array(label)\n",
    "    trainData2, testData2 = label[train], label[test]\n",
    "    \n",
    "    SVM = SVC(kernel = 'linear', C = 1)\n",
    "    model = SVM.fit(trainData, trainData2)\n",
    "    prediksi = model.predict(testData)\n",
    "    \n",
    "#     print(\"\\nSVM Prediction  : \\n\", prediksi)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix: \\n\", metrics.confusion_matrix(testData2, prediksi))\n",
    "   \n",
    "    accuracy.append(accuracy_score(testData2, prediksi))\n",
    "    \n",
    "    print(\"\\nSVM Accuracy : \", accuracy_score(testData2, prediksi))\n",
    "    print()\n",
    "    \n",
    "    label_target = ['positif','negatif']\n",
    "    print(metrics.classification_report(testData2, prediksi, labels=[1,-1]))#Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[180  38]\n",
    "#[ 25 346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba7b8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.893, Precission : 0.826, Recall : 0.878, F1 Score : 0.851\n"
     ]
    }
   ],
   "source": [
    "accuracy = (180+346)/(180+38+25+346)\n",
    "precission = (180)/(180+38)\n",
    "recall = (180)/(180+25)\n",
    "f1score = (2*(recall*precission))/(recall+precission)\n",
    "\n",
    "print(\"Accuracy : %.3f, Precission : %.3f, Recall : %.3f, F1 Score : %.3f\" %(accuracy, precission, recall, f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370b89a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
